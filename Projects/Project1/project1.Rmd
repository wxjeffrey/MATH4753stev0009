---
title: "Project 1"
author: "Jeffrey Stevenson"
date: "`r Sys.Date()`"
output:
  html_document:
    code_folding: show
    csl: biomed-central.csl
    df_print: paged
    fig_caption: yes
    fig_height: 6
    fig_width: 7
    number_sections: yes
    theme: journal
    toc: yes
    toc_float: yes
  word_document:
    toc: yes
    toc_depth: '4'
  pdf_document:
    df_print: kable
    fig_caption: yes
    fig_height: 6
    fig_width: 7
    highlight: tango
    toc: yes
    toc_depth: 4
#bibliography: project.bib
abstract: This project is all about analysing the SWDEFECTS file using R and probability theory. You will need to change the headings to reflect the nature of the project intentions. Re write this abstract as the last thing you do.
---

<center>

![Jeffrey Stevenson](jeffrey.jpeg "My Picture"){ width=20% }

</center>


---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Introduction to the data

## Data and variables(see MS pg. 77,125)
 
This data file contains 498 modules of software code written in C for NASA spacecraft instruments. For each of these modules, the code was evaluated line-by-line to check for defects. If a defect exists, it is labeled with "true", otherwise it is labeled with "false". Various other methods were also used to predict if a module has a defect or not (lines of code, cyclomatic complexity, essential complexity, and design complexity). Each method has a corresponding variable that is labeled with "yes" when a defect exists and "no" when there is no defect. We will be evaluating these different methods and using probabilities to understand how effective they are. 

## Summary Table 

```{r echo = FALSE, results = 'asis'}
sumtable <- matrix(c(" ","False","True","No","_a_","_b_","Yes","_c_","_d_"," "," "," "),nrow = 4, ncol=3,byrow=TRUE)
colnames(sumtable) <- c(" ","_Module_ _Has_ _Defects_","_Module_ _Has_ _Defects_")
rownames(sumtable) <- c(" ","_Algorithm_","_Predicts_","_Defects_")
sumtable <- as.table(sumtable)

library(knitr)
kable(sumtable, caption = "__Summary Table for Evaluating Defect Prediction Algorithms__")
```


### Make formulae 

1. Accuracy: $P(Algorithm \ is \ correct) = \frac{a+d}{a+b+c+d}$

2. Detection Rate: $P(predict \ defect| module \  has \ defect) = \frac{d}{b+d}$

3. False Alarm Rate: $P(predict \ defect| module \  has \ no \ defect) = \frac{c}{a+c}$

4. Precision: $P(module \ has \ defect |predict \ defect) = \frac{d}{c+d}$

# R functions

```{r accuracy}
acc=function(a,b,c,d)
{
  (a+d)/(a+b+c+d)
}
```

```{r detecton}
detect=function(b,d)
{
  (d)/(b+d)
}
```

```{r alarm}
falarm=function(a,c)
{
  (c)/(a+c)
}
```

```{r precision}
prec=function(c,d)
{
  (d)/(c+d)
}
```


# Create the tables in Figure SIA3.1

The tables do not have to be formatted exactly as those in the book. Have the functions produce a suitable barplot also. 
In other wordss you will use R code to make these tables (again formatting does not have to be the same as the book)

As a guide and help -- see code below

```{r }
swd=read.csv("swdefects.csv")
head(swd)
tab=with(swd, table(predict.loc.50,defect))
barplot(tab, beside=TRUE, leg=TRUE)
tab2=addmargins(tab)
tab2
```

```{r }
#read data
swd=read.csv("SWDEFECTS.csv")
#check that data is correctly imputed
head(swd)
# getting the data for loc50 and creating the margings of it
loc50=with(swd, table(predict.loc.50,defect))
loc50.1=addmargins(loc50)
# getting the data for EVG and creating the margings of it
EVG=with(swd, table(predict.evg.14.5,defect))
EVG.1=addmargins(EVG)
# getting the data for IVG and creating the margings of it
IVG=with(swd, table(predict.ivg.9.2,defect))
IVG.1=addmargins(IVG)
# getting the data for VG and creating the margings of it
VG=with(swd, table(predict.vg.10,defect))
VG.1=addmargins(VG)
# Printing the tables with margins
#loc50
loc50.1
#VG
VG.1
#EVG
EVG.1
#IVG
IVG.1
#Creating barplots for tables without margin
#loc50
barplot(loc50, beside=TRUE, leg=TRUE)
#EVG
barplot(EVG, beside=TRUE, leg=TRUE)
#IVG
barplot(IVG, beside=TRUE, leg=TRUE)
#VG
barplot(VG, beside=TRUE, leg=TRUE)
```



# Create the corrected table on page 127 (there are mistakes in it), TABLE SIA3.3

Using the functions you have made **or otherwise**, create the corrected table (SIA3.3) in an R chunk -- that is, you will make an R function to create the table.
 
You can call this table `tab3`

Now create a function `mybar()`that will have as its input variables

>
    1. tab ( this will be a n by m table) - like `tab3`
    2. dec ( accuracy of the decimal output ) -- like `dec=4` for example would mean 4 decimal places (use `round()`)
    

    
The function will need to create two things

>
    1. A barplot of the table
    2. Commandline output in the form of a list containing the table
    
    
![](jeffrey.jpeg){ width=70% }

